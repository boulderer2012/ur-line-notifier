import os
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime

# GitHubä¸Šã®previous.jsonã®ãƒ‘ã‚¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ã‹ã™ãªã‚‰ç›¸å¯¾ãƒ‘ã‚¹ã§OKï¼‰
DATA_PATH = "previous.json"

# URã®æ–°ç€ç‰©ä»¶ã‚’å–å¾—ï¼ˆSeleniumãªã—ï¼ï¼‰
def fetch_ur_listings():
    url = "https://www.ur-net.go.jp/chintai/information/"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    base_url = "https://www.ur-net.go.jp"
    links = soup.select("a.item_link.fc_blue.item_cell")

    listings = []
    for link in links:
        text = link.get_text(strip=True)
        href = link.get("href")
        if "æ–°ç¯‰è³ƒè²¸ä½å®…" in text:
            listings.append({"title": text, "url": base_url + href})
    return listings

# å‰å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
def load_previous():
    if os.path.exists(DATA_PATH):
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

# ä»Šå›ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
def save_current(data):
    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# æ–°ç€ç‰©ä»¶ã¨æ›´æ–°æƒ…å ±ã‚’åˆ†é¡ã—ã¦æ¤œå‡º
def detect_new_listings(current, previous):
    previous_titles = {item["title"] for item in previous}
    new_items = [item for item in current if item["title"] not in previous_titles]

    new_arrivals = []
    updates = []

    for item in new_items:
        title = item["title"]
        if "æ–°è¦å…¥å±…è€…å‹Ÿé›†" in title:
            new_arrivals.append(item)
        elif any(kw in title for kw in ["æŠ½é¸å‹Ÿé›†", "å¿œå‹ŸçŠ¶æ³", "æŠ½é¸çµæœ"]):
            updates.append(item)

    return new_arrivals, updates

# Renderã‚’èµ·å‹•ï¼ˆWebhookã‚’å©ãï¼‰
def ping_render():
    render_url = os.environ.get("RENDER_WEBHOOK_URL")
    if not render_url:
        print("âŒ RENDER_WEBHOOK_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    try:
        res = requests.get(render_url)
        print(f"ğŸš€ Renderèµ·å‹•ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {res.status_code}")
    except Exception as e:
        print(f"âš ï¸ Renderèµ·å‹•ã«å¤±æ•—: {e}")

def main():
    current = fetch_ur_listings()
    previous = load_previous()
    new_arrivals, updates = detect_new_listings(current, previous)

    if new_arrivals:
        print(f"ğŸ”” æ–°ç€ç‰©ä»¶ {len(new_arrivals)} ä»¶æ¤œå‡ºï¼Renderã‚’èµ·å‹•ã—ã¾ã™ï¼")
        for item in new_arrivals:
            print(f"ãƒ»{item['title']}")
        ping_render()
        save_current(current)
    elif updates:
        print(f"ğŸ“„ æ›´æ–°æƒ…å ± {len(updates)} ä»¶ã‚ã‚Šã¾ã—ãŸï¼ˆRenderã¯èµ·å‹•ã—ã¾ã›ã‚“ï¼‰")
        for item in updates:
            print(f"ãƒ»{item['title']}")
        save_current(current)
    else:
        print("ğŸ“­ æ–°ç€ãªã—ã€‚Renderã¯èµ·å‹•ã—ã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()
